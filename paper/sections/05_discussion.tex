\section{Discussion}

Our findings suggest that the subjective character of qualia---the fact that sensory experiences feel like \textit{something}, and that my red might differ from yours---can be understood as a consequence of information processing architecture, not as a mysterious extra ingredient.

\subsection{Two Types of Novelty}

A central insight from our experiments is the distinction between \textbf{Sensory Novelty} and \textbf{Semantic Novelty}:

\begin{table*}[t]
    \centering
    \small
    \begin{tabular}{@{}lp{3.2cm}p{4cm}@{}}
        \hline
        \textbf{Type} & \textbf{Definition}           & \textbf{Example}                \\
        \hline
        Sensory       & Novel signal \textit{format}  & RGB to grayscale-trained system \\
        Semantic      & Novel signal \textit{content} & New object category             \\
        \hline
    \end{tabular}
    \caption{Sensory vs. Semantic Novelty. The ``Wow'' signal measures sensory novelty---surprise at format, not content.}
    \label{tab:novelty_types}
\end{table*}

Standard machine learning metrics (e.g., classification accuracy, perplexity) measure semantic novelty: does the model recognize the object? Our ``Wow'' signal measures something different---does the model recognize the \textit{format}? A grayscale-trained model can correctly identify a red apple (low semantic novelty) while still experiencing the chromatic format as profoundly unfamiliar (high sensory novelty). This dissociation is precisely what makes qualia puzzling: Mary knows everything about red, yet seeing it is still surprising.

\subsection{The Architecture of Subjectivity}

Our framework suggests that qualia emerge from a specific architectural pattern:

\begin{table*}[t]
    \centering
    \small
    \begin{tabular}{@{}lll@{}}
        \hline
        \textbf{Component} & \textbf{Name}                        & \textbf{Role}              \\
        \hline
        Vision Encoder     & Sensory Encoder (Fixed Biology)      & Phylogenetic hardware      \\
        MLPs               & Modality Projector (Gain Interface)  & Tunable format translation \\
        Language Model     & Propositional Decoder (Plastic Mind) & Ontogenetic software       \\
        \hline
    \end{tabular}
    \caption{MaryVLM components and their philosophical roles.}
    \label{tab:architecture}
\end{table*}

The key insight is that these components exist on a \textbf{spectrum of plasticity}, not a binary frozen/trainable distinction:

\paragraph{Phylogenetic Processing (Relatively Fixed)}
The Sensory Encoder represents evolutionarily-determined processing---structures like cone cells, color-opponent channels, and V1 organization that are largely determined by genetics. In our model, we freeze these weights to simulate their relative fixity. However, ``phylogenetic'' does not mean ``frozen.'' Studies of color-deficient corrective glasses show that even ``hardcoded'' visual hardware can be modulated. \citet{MartinezDomingo2019} found that EnChroma glasses do not restore normal color vision but rather shift the stimulus to increase chromatic contrast, allowing existing hardware to better differentiate signals that previously appeared identical. The hardware itself does not change; the input is transformed.

\paragraph{Ontogenetic Processing (Plastic Mind)}
The Language Model represents knowledge acquired through experience---language, concepts, and associations learned during development and life. This system is highly plastic, continuously updated by experience. Mary's ``textbook knowledge'' about color resides here.

\paragraph{The Gain Interface (Blurred Boundary)}
The Modality Projector represents a critical intermediate layer---the interface where phylogenetic signals are translated into ontogenetic representations. Crucially, \citet{Rabin2020} found that after anomalous trichromats wore color-corrective filters for two weeks, they showed improved chromatic responses \textit{even when not wearing the glasses}. This suggests the adult visual system retains plasticity at this interface: the ``hardcoded'' pathways remain, but the gain or weighting between sensory input and conceptual processing can be re-tuned when provided with high-contrast signals previously missing.

In MaryVLM, this corresponds to the Modality Projector---trainable layers that learn to amplify, suppress, or transform specific dimensions of the sensory manifold. The ``Wow'' signal is strongest at this interface precisely because it is where format translation occurs.

\begin{table*}[t]
    \centering
    \small
    \begin{tabular}{@{}llll@{}}
        \hline
        \textbf{Layer} & \textbf{Component}                   & \textbf{Plasticity} & \textbf{Biological Analog}          \\
        \hline
        Phylogenetic   & Sensory Encoder                      & Relatively fixed    & Cones, V1, color-opponent channels  \\
        Gain Interface & Modality Projector                   & Tunable             & Attentional gain, filter adaptation \\
        Ontogenetic    & Propositional Decoder (Plastic Mind) & Highly plastic      & Language, concepts, associations    \\
        \hline
    \end{tabular}
    \caption{Three-layer plasticity framework. Qualia emerge at the Gain Interface, where fixed sensory formats meet plastic conceptual systems.}
    \label{tab:plasticity}
\end{table*}

\subsection{Why Qualia Feel Private}

The Inverted Spectrum has long been cited as a puzzle for functionalism: how can two agents produce identical behaviors while having different internal experiences? Our results demonstrate that the Inverted Spectrum is \textbf{physically possible}---at least in artificial systems:

\begin{itemize}
    \item Two MaryVLM agents with different random seeds achieve identical VQA accuracy (functional equivalence).
    \item Yet their internal representations of ``red'' occupy different geometric positions (structural disparity).
    \item The external function is shared; the internal geometry is private.
\end{itemize}

However, we must be careful about generalizing to biological systems. Our model exhibits high plasticity in the Conceptual Bridge---the random seed determines the learned geometry, and there are no constraints enforcing cross-agent alignment. Human brains may be different in important ways:

\paragraph{Biological Constraints on Inversion}
Unlike our randomly initialized MLPs, the human visual system develops under strong biological and environmental constraints. Color-opponent channels, cortical organization, and shared developmental pressures may produce more consistent internal geometries across individuals than our model suggests. Empirical work by \citet{Kawakita2025} used optimal transport methods to compare color similarity structures across participants and found that color-neurotypical individuals show \textit{alignable} color spaces at the group level---suggesting that human color qualia may be more consistent than the Inverted Spectrum hypothesis implies. Notably, color-blind participants could \textit{not} be aligned with neurotypical individuals, providing quantitative evidence that inter-individual differences do exist when biological constraints differ.

\paragraph{Structural vs. Relational Qualia}
Our analysis leaves open an important philosophical question: does the ``privateness'' of qualia reside in \textit{absolute} geometric positions (structural) or in \textit{relational} patterns (how red relates to blue, green, etc.)? We measure Procrustes disparity, which captures geometric misalignment, but Centered Kernel Alignment (CKA) measures relational similarity. Interestingly, our agents show high Procrustes disparity but moderate CKA---suggesting their color spaces are \textit{rotated} relative to each other but preserve similar \textit{relationships}. Whether subjective experience tracks absolute positions or relational structure remains an open question that our framework can test but not definitively answer.

\subsection{Unifying the ``Replies'' to Mary's Room}

Philosophers have proposed various responses to Jackson's Knowledge Argument. Remarkably, MaryVLM provides a unified framework in which each ``reply'' corresponds to a distinct computational component:

\paragraph{The Ability Hypothesis} \citep{Nemirow1990}
Lewis and Nemirow argued that Mary gains not new propositional knowledge, but new \textit{abilities}: to recognize, remember, and imagine red. In MaryVLM terms, this maps directly to \textbf{VQA performance}. After chromatic exposure (continued training on RGB), $M_{gray}^{cont}$ shows improved accuracy on color-related questions. The ``ability'' is the Conceptual Bridge's learned capacity to translate chromatic formats into correct verbal responses.

\paragraph{The Acquaintance Hypothesis}
Conee proposed that Mary gains \textit{knowledge by acquaintance}---direct experiential contact with redness, distinct from knowledge-that or knowledge-how. In our framework, acquaintance corresponds directly to the \textbf{``Wow'' signal}. The Sensory Encoder always produced chromatic representations, but the Modality Projector never encountered them during training. Upon release, the downstream system faces a representation it has never seen---and the measurable cost of this encounter (Mahalanobis distance spike) is the computational signature of ``becoming acquainted.'' The Wow signal \textit{is} acquaintance, operationalized.

\paragraph{Old Fact / New Guise} \citep{Loar1990}
Loar and Papineau argued that Mary learns no new facts; she merely grasps old facts under a new \textit{mode of presentation}. This aligns precisely with our architecture: the propositional content (``roses are red'') was always in the \textbf{Propositional Decoder}. What changes is the format in which this content is accessed. The ``new guise'' is the chromatic representation from the Sensory Encoder---a different input pathway to the same semantic knowledge.

\paragraph{Synthesis}
These replies are not competitors but descriptions of different components of the same system:

\begin{table*}[t]
    \centering
    \small
    \begin{tabular}{@{}llp{5cm}@{}}
        \hline
        \textbf{Reply}     & \textbf{MaryVLM Component} & \textbf{Computational Interpretation}                             \\
        \hline
        Ability Hypothesis & VQA Performance            & Improved VQA after chromatic fine-tuning                          \\
        Acquaintance       & ``Wow'' Signal             & Mahalanobis distance spike when encountering novel representation \\
        Old Fact/New Guise & Propositional Decoder      & Same semantic content, different input pathway                    \\
        \hline
    \end{tabular}
    \caption{Mapping philosophical replies to MaryVLM components.}
    \label{tab:replies}
\end{table*}

Thus the ``Wow'' signal plays a dual role: it \textit{is} the Acquaintance Hypothesis operationalized, \textit{and} it reveals something that the other perspectives miss---the measurable cost of format translation. The Ability Hypothesis concerns what Mary can \textit{do} after; the Old Fact/New Guise concerns the \textit{content} of her knowledge; but Acquaintance concerns the \textit{moment of contact itself}. That moment is the Wow signal: the metabolic signature of encountering a representation your system has never processed before.

\subsection{Limitations}

Several limitations constrain our conclusions:

\begin{itemize}
    \item \textbf{Scale}: Our model is small (135M LLM parameters). Larger models may show different dynamics.
    \item \textbf{Simplicity of stimuli}: We used synthetic color-shape images. Natural images introduce confounds (textures, gradients) that may complicate interpretation.
    \item \textbf{Single modality}: We tested only vision. Generalizing to auditory or tactile qualia requires further work.
    \item \textbf{No temporal dynamics}: We measure a single ``Release'' event. Biological qualia adapt over time; our model does not capture habituation.
\end{itemize}

\subsection{Future Directions}

Several extensions suggest themselves:

\begin{enumerate}
    \item \textbf{Chromatic fine-tuning}: What happens to the ``Wow'' signal as Mary learns to process color? Does it decay as the Conceptual Bridge adapts?
    \item \textbf{Multi-modal qualia}: Extend to auditory stimuli (a grayscale-trained model exposed to audio) to test whether the ``Wow'' signal is modality-general.
    \item \textbf{Collective Mary}: Train multiple Marys with private experiences but a shared language, modeling how communities develop shared concepts despite private qualia.
    \item \textbf{Attention and gating}: Investigate whether the ``Wow'' signal modulates attention or ``promotes'' information to higher processing stages, as predicted by Global Workspace theory.
\end{enumerate}

